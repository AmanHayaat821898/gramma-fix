from typing import Dict, List

import numpy
from allennlp.predictors import Predictor
from allennlp.models import Model
from allennlp.common.util import sanitize
from overrides import overrides
from allennlp.common.util import JsonDict
from allennlp.data import DatasetReader, Instance, Token
from allennlp.data.fields import TextField, SequenceLabelField
from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter
from allennlp.data.tokenizers.word_splitter import JustSpacesWordSplitter
from allennlp.models import Model
from utils.helpers import START_TOKEN


@Predictor.register("gec-predictor")
class GecPredictor(Predictor):
    """
    A Predictor for generating predictions from GECtor.

    Note that currently, this is unable to handle ensemble predictions.
    """
    def __init__(self, model: Model,
                 dataset_reader: DatasetReader,
                 language: str = 'en_core_web_sm',
                 iterations: int = 3) -> None:
        super().__init__(model, dataset_reader)
        #self._tokenizer = SpacyWordSplitter(language=language, pos_tags=True)
        self._tokenizer = JustSpacesWordSplitter()
        self._iterations = iterations

    def predict(self, sentence: str) -> JsonDict:
        return self.predict_json({"sentence": sentence})

    def predict_batch(self, sentences: List[str]) -> JsonDict:
        return self.predict_batch_json([{"sentence": sentence} for sentence in sentences])

    @overrides
    def predict_instance(self, instance: Instance) -> JsonDict:
        for i in range(self._iterations):
            outputs = self._model.forward_on_instance(instance)
            # integrate predictions back into instance for next iteration
        return sanitize(outputs)

    @overrides
    def _json_to_instance(self, json_dict: JsonDict) -> Instance:
        """
        Expects JSON that looks like ``{"sentence": "..."}``.
        Runs the underlying model, and adds the ``"words"`` to the output.
        """
        sentence = json_dict["sentence"]
        tokens = self._tokenizer.split_words(sentence)
        # Add start token to front
        tokens = [Token(START_TOKEN)] + tokens
        return self._dataset_reader.text_to_instance(tokens)


    @overrides
    def predictions_to_labeled_instances(self,
                                         instance: Instance,
                                         outputs: Dict[str, numpy.ndarray]) -> List[Instance]:
        """
        This method creates an instance out of the predictions generated by the model.
        """
        NotImplemented