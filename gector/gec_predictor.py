from typing import Dict, List

import numpy
from allennlp.predictors import Predictor
from allennlp.models import Model
from allennlp.common.util import sanitize
from overrides import overrides
from allennlp.common.util import JsonDict
from allennlp.data import DatasetReader, Instance
from allennlp.data.fields import TextField, SequenceLabelField
from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter
from allennlp.models import Model

from utils.helpers import PAD, UNK


@Predictor.register("gec-predictor")
class GecPredictor(Predictor):
    """
    A Predictor for generating predictions from GECtor.

    Note that currently, this is unable to handle ensemble predictions.
    """
    def __init__(self, model: Model,
                 dataset_reader: DatasetReader,
                 language: str = 'en_core_web_sm',
                 iterations: int = 3) -> None:
        super().__init__(model, dataset_reader)
        self._tokenizer = SpacyWordSplitter(language=language, pos_tags=True)
        self._iterations = iterations

    def predict(self, sentence: str) -> JsonDict:
        return self.predict_json({"sentence": sentence})

    def predict_batch(self, sentences: List[str]) -> JsonDict:
        return self.predict_batch_json([{"sentence": sentence} for sentence in sentences])

    @overrides
    def predict_instance(self, instance: Instance) -> JsonDict:
        for i in range(self._iterations):
            outputs = self._model.forward_on_instance(instance)
            # integrate predictions back into instance for next iteration
        return sanitize(outputs)

    @overrides
    def _json_to_instance(self, json_dict: JsonDict) -> Instance:
        """
        Expects JSON that looks like ``{"sentence": "..."}``.
        Runs the underlying model, and adds the ``"words"`` to the output.
        """
        sentence = json_dict["sentence"]
        tokens = self._tokenizer.split_words(sentence)
        return self._dataset_reader.text_to_instance(tokens)

    def get_token_action(self, token, index, prob, sugg_token):
        """Get list of suggested actions for token."""
        # cases when we don't need to do anything
        if prob < self.min_error_probability or sugg_token in [UNK, PAD, '$KEEP']:
            return None

        if sugg_token.startswith('$REPLACE_') or sugg_token.startswith('$TRANSFORM_') or sugg_token == '$DELETE':
            start_pos = index
            end_pos = index + 1
        elif sugg_token.startswith("$APPEND_") or sugg_token.startswith("$MERGE_"):
            start_pos = index + 1
            end_pos = index + 1

        if sugg_token == "$DELETE":
            sugg_token_clear = ""
        elif sugg_token.startswith('$TRANSFORM_') or sugg_token.startswith("$MERGE_"):
            sugg_token_clear = sugg_token[:]
        else:
            sugg_token_clear = sugg_token[sugg_token.index('_') + 1:]

        return start_pos - 1, end_pos - 1, sugg_token_clear, prob

    @overrides
    def predictions_to_labeled_instances(self,
                                         instance: Instance,
                                         outputs: Dict[str, numpy.ndarray]) -> List[Instance]:
        """
        This method creates an instance out of the predictions generated by the model.
        """
        NotImplemented